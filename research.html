<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.9.18, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.9.18, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/logo.png" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Research</title>
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css?v=phi3Mc"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css?v=phi3Mc" type="text/css">

  
  
  
</head>
<body>
  
  <section data-bs-version="5.1" class="menu menu1 cid-sDmoM1B40a" once="menu" id="menu1-b">
    

    <nav class="navbar navbar-dropdown navbar-fixed-top navbar-expand-lg">
        <div class="container">
            <div class="navbar-brand">
                
                <span class="navbar-caption-wrap"><a class="navbar-caption text-black text-primary display-7" href="index.html">Dongxiao Zhu</a></span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbarSupportedContent" data-bs-target="#navbarSupportedContent" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <div class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#header11-6">Home</a></li><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="research.html">Research</a></li>
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="publications.html">Publication</a></li>
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="teaching.html">Teaching</a>
                    </li></ul>
                
                
            </div>
        </div>
    </nav>
</section>

<section data-bs-version="5.1" class="content14 cid-sEd6OGNHu7" id="content14-p">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7">My recent research thrusts lie in trustworthy Artificial Intelligence (AI) and AI Safety with human-trust inspired and community driven innovations for social good, such as good health and wellbeing, mobility equity, and, zero hunger. My&nbsp;<strong>foundational AI research</strong> focuses on <strong>explainability</strong>, <strong>adversarial robustness</strong>, and <strong>fairness</strong> of deep neural networks (DNNs), collectively among others referring to trustworthy AI. Recent literature has seen marked performance improvement of AI models on benchmark datasets, nevertheless overlooking trustworthiness when deploying the AI models in safety and security-critical real-world scenarios. Our foundational AI research subsequently motivates&nbsp;<strong>use-inspired AI research</strong> to tackle some of more pressing human-centered and community-driven issues (e.g., transparency, fairness, and disparities in health and mobility) via efficiently leveraging the limited resources to improve accessibility of the socially vulnerable groups, fostering a thriving community. In addition, my research interest also lies in <strong>AI for Science</strong> where I collaborate with researchers from life, physical and social science domains to design tailor-made AI algorithms to solve their real-world research problems.&nbsp; &nbsp;<br><strong><br></strong><span style="font-size: 19.2px;"><strong>Interpretable Machine Learning and</strong></span><strong>&nbsp;Explainable AI (XAI)</strong> research attempts to understand (1)&nbsp;<strong>from developer perspective</strong> how information flows from input to output and what Deep Neural Network learns, and (2) from both <strong>end user</strong> and <strong>developer perspectives</strong>, what does DNN 'see' in the image or 'comprehend' in natural language. We have made original contributions to both directions of current XAI research: <strong style="font-size: 1.2rem;">explainable model prediction</strong><span style="font-size: 1.2rem;"> and&nbsp;</span><strong style="font-size: 1.2rem;">interpretable feature representation learning</strong><span style="font-size: 1.2rem;">.</span><div>
</div></h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-thvtDTDnCV" id="image1-1y">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <img src="assets/images/methods-1076x409.jpg" alt="Mobirise">
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Attentive Class Activation Token (AttCAT)</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Explaining Transformer prediction</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">A novel Transformer explanation technique via attentive&nbsp;class activation tokens, aka, AttCAT, leveraging encoded features, their gradients, and their attention weights to generate a faithful and confident explanation for Transformer’s output<br>Qiang, Y, Pan, D, Li, C, Li, X, Jang, R, and <strong>Zhu, D</strong>. (2022) <a href="https://openreview.net/pdf?id=cA8Zor8wFr5" class="text-primary">AttCAT: Explaining Transformers via Attentive Class Activation Tokens</a>. In the Proceedings of Thirty-sixth Conference on Neural Information Processing Systems (<strong>NuerIPS-22</strong>), New Orleans, LA, USA.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEoldobSNS" id="image1-17">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="assets/files/ijcai21_CRC.pdf"><img src="assets/images/discrimnating-793x292.jpg" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Adversarial Gradient Integration (AGI)</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Explaining DNN prediction</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">Adversarial Gradient Integration (AGI) to explain the attribution of each pixel or each token to the DNN’s class prediction via integrating gradients from adversarial examples to the test examples for the target class.<br>Pan, D, Li, X and <strong>Zhu, D. </strong>(2021) <a href="assets/files/ijcai21_CRC.pdf" class="text-primary">Explaining Deep Neural Network Models with Adversarial Gradient Integration</a>. In 30th International Joint Conference on Artificial Intelligence (<strong>IJCAI-21</strong>), Montreal, Canada.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEoj0IDD8I" id="image1-16">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://www.ijcai.org/proceedings/2020/373"><img src="assets/images/explain-ex-625x195.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Interpretable Feature Mapping (IFM)</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Interpretable feature mapping</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">An interpretable neural network architecture allowing interpretable feature mapping via dissecting latent layers guided by aspects and demonstrated applications in explainable recommender’s system.<br>Pan, D, Li, X, Li, X and <strong>Zhu, D.</strong> (2020) <a href="https://www.ijcai.org/Proceedings/2020/0373.pdf" class="text-primary">Explainable recommendation via interpretable feature mapping and evaluating explainability</a>. In the proceedings of 29th International Joint Conference on Artificial Intelligence (<strong>IJCAI-20</strong>), Yokohama, Japan.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content14 cid-sEooiDLZnC" id="content14-18">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7"><strong>Adversarial robustness of DNNs </strong>research: we develop novel feature representation learning approaches to improve the adversarial robustness of the DNN via <strong>learning compact feature representation</strong>. We achieve this goal via designing novel <strong>natural training</strong> and <strong>adversarial training</strong> schemes. We also design adversarial attack and defense strategies to improve the safety of <strong>Large Language Models</strong> (LLMs).</h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-uuRFOEUNZg" id="image1-22">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="research.html"><img src="assets/images/illustration-1256x469.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Illustrations of hijacking attack during ICL</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Adversarial In-Context Learning</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">This work introduces a novel transferable attack against In-Context-Learning to hijack LLMs to generate the target response or jailbreak.&nbsp; We also propose a defense strategy against hijacking attacks through the use of extra clean demos, which enhances the robustness of LLMs during ICL.<br>
<br>Qiang, Y., Zhou, X. and <strong>Zhu, D.</strong>, 2023. <a href="https://arxiv.org/abs/2311.09948" class="text-primary">Hijacking Large Language Models via Adversarial In-Context Learning</a>. arXiv e-prints, pp.arXiv-2311.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-uuRFMxv69x" id="image1-21">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="research.html"><img src="assets/images/example-1256x819.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Illustration of our learning to poison attack</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Learning to Poison Large Language Models During Instruction Tuning</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">A novel gradient-guided backdoor trigger learning (GBTL) algorithm to identify adversarial triggers efficiently, ensuring an evasion of detection by conventional defenses while maintaining content integrity.<br><br>Qiang Y, Zhou X, Zade SZ, Roshani MA, Khanduri P, Zytko D, Zhu D. <strong><a href="https://arxiv.org/abs/2402.13459" class="text-primary">Learning to poison large language models during instruction tuning</a></strong>. arXiv preprint arXiv:2402.13459. 2024 Feb 21.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEopdyQtEz" id="image1-19">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17030/16837"><img src="assets/images/picture4-1076x424.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Probabilistically Compact (PC) loss
<br>with logit constraints</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Probabilistically Compact (PC) loss&nbsp;</strong><strong style="font-size: 2rem;">with logit constraints</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">A new Probabilistically Compact loss (PC loss) to directly enlarge the probability gap between true class and false classes to improve adversarial robustness of DNNs.
<br>Li, X, Li, X, Pan,D and <strong>Zhu, D.</strong> (2021) <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17030" class="text-primary">Improving adversarial robustness via probabilistically compact loss with logit constraints</a>. In the proceedings of Thirty-Five AAAI Conference on Artificial Intelligence (<strong>AAAI-21</strong>), virtual conference.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content14 cid-sEoz0piasa" id="content14-1b">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7"><strong>Fairness of DNNs </strong>research: this includes mitigation of <strong>class-imbalance</strong> and <strong>group-imbalance</strong> issues. To mitigate group-imbalance issue, we developed Multi-Task Learning (MTL) algorithms to predict time-to-event and ordinal outcomes. To overcome class-imbalance issue, we developed a cost-sensitive approach to design optimal weight schemes. We explicated the learning property of logistic and softmax loss functions by analyzing the necessary condition (e.g., gradient equals to zero) after training converges.</h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-uuRIUBi1jK" id="image1-23">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="research.html"><img src="assets/images/architecture-1256x649.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">The Debiased Self-Attention (DSA) framework.</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Fairness-aware Vision Transformer&nbsp;&nbsp;</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">We developed Debiased Self-Attention (DSA), is a fairness-through-blindness approach that enforces ViT to eliminate spurious features correlated with the sensitive attributes for bias mitigation. Adversarial examples are leveraged to locate and mask the spurious features in the input image patches with attention weights alignment.<br><br>Qiang Y, Li C, Khanduri P, Zhu D. <a href="https://arxiv.org/abs/2301.13803" class="text-primary">Fairness-aware vision transformer via debiased self-attention</a>. <strong>ECCV-24</strong>.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-t3JQn0HtFs" id="image1-1m">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <img src="assets/images/celeba-787x516.png" alt="Mobirise">
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Attribution map generated by CIA</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Counterfactual interpolation augmentation&nbsp;</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">A novel generative data augmentation approach to create counterfactual samples to make the sensitive attribute and the target attribute d-separated to achieve fairness and the interpolation path ensures attribution based explainability.&nbsp;<br><br>Qiang, Y, Li, C, Brocanelli, M, <strong>Zhu, D.</strong> (2022) <a href="https://www.ijcai.org/proceedings/2022/0103.pdf" class="text-primary">Counterfactual Interpolation Augmentation (CIA): A Unified Approach to Enhance Fairness and Explainability of DNN</a>. In the proceedings of 31st International Joint Conference on Artificial Intelligence (<strong>IJCAI-22</strong>), Messe Wien, Vienna, Austria.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEopevIV1t" id="image1-1a">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://ojs.aaai.org//index.php/AAAI/article/view/5907"><img src="assets/images/cifartsne-1-1076x551.jpg" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">In-Training Representation Alignment (ITRA)</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Learning property of cross-entropy loss based DNNs</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">A novel reweighted logistic loss for multi-class classification to improve ordinary logistic loss by focusing on learning hard non-target classes (target vs. non-target class in one-vs.-all) <br>Li, X, Li, X, Pan,D and <strong>Zhu, D.</strong> (2020) <a href="https://ojs.aaai.org//index.php/AAAI/article/view/5907" class="text-primary">On the learning behavior of logistic and softmax losses for deep neural networks</a>. In the proceedings of Thirty-Fourth AAAI Conference on Artificial Intelligence (<strong>AAAI-20</strong>), New York, USA.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content14 cid-sEoeeScyM9" id="content14-13">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7"><strong>Use-inspired Trustworthy AI Research: </strong>Healthcare data is featured with <strong>high dimension</strong>, <strong>heterogeneity</strong> and <strong>label scarcity</strong>. Our AI applications in healthcare research lies in patient subgroup identification and risk factor prioritization. To overcome label scarcity issue, we used primary labels together with auxiliary labels as regularization to learn features and improve prediction performance. We also tackle the label scarcity issue using semi-supervised and active learning approaches using EHR data. To address the data heterogeneity issue, we developed multi-task deep feature learning approaches to learn general features for predicting population-wide and task-specific features for predicting group-specific health outcomes. When patient groups are undefined, we generalized it with a deep mixture neural network model to predict health outcomes for latent groups. Our recent research thrust lies in trustworthy AI algorithms with community driven innovations for social good, such as health and wellbeing, mobility equity, security and privacy.</h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEunmEIQBF" id="image1-1c">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233047/"><img src="assets/images/3269941f3-641x201.jpg" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Deep Mixture Neural Network (DMNN) predictive model</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Clinical outcome predictive model with patient stratification</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">Existing DNN predictive models either relies on pre-defined patient subgroups or one-size-fit-all. We develop a novel Deep Mixture Neural Network based predictive models for patient stratification and group-specific risk factor prioritization.&nbsp;<br>Li, X, <strong>Zhu, D*</strong> and Levy, P (2020) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233047/" class="text-primary">Predicting clinical outcomes with patient stratification via deep mixture neural networks</a>. American Medical Informatics Association (AMIA-20) Summit on Clinical Research Informatics, Houston, USA. (Best Student Paper Award, *Corresponding Autor) PubMed <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233047/" class="text-primary">32477657</a><br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEunnrAxQ1" id="image1-1d">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://dongxiaozhu.github.io/BIBM19-ObesityRiskFactors.pdf"><img src="assets/images/picture1-647x342.jpg" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Multi-Task Learning (MTL) for risk factor prioritization&nbsp;</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Prioritizing multi-level risk factors for obesity</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">Many behavior disorders, e.g., obesity, are multi-faced health outcome and risk factors are highly specific to certain subpopulation groups residing in different geospatial districts. We develop a Multi-Task Learning (MTL) approach for prioritize multi-level risk factors.&nbsp;<br>Wang, Dong, M, Towner, E and Zhu, D. (2019) <a href="https://dongxiaozhu.github.io/BIBM19-ObesityRiskFactors.pdf" class="text-primary">Prioritization of multi-level risk factors for obesity</a>. In the proceedings of 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM-19), 1065-1072.<br><br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEunoqMluM" id="image1-1e">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://arxiv.org/pdf/1906.03691.pdf"><img src="assets/images/picture2-623x352.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Age effect identification from fMRI&nbsp;</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Aging effect from human fetal brain using spontaneous fMRI</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">We design a deep 3D CNN to fetal blood oxygen-level dependence (BOLD) resting-state fMRI data to isolate the variation in fMRI signals that relates to the age effect.<br>Li, X., Hect, J., Thompson, J. and Zhu, D. (2020). <a href="https://arxiv.org/pdf/1906.03691.pdf" class="text-primary">Interpreting age effects of human fetal brain from spontaneous fMRI using deep 3D convolutional neural networks</a>. IEEE International Symposium on Biomedical Imaging (ISBI-20), Iowa City, USA.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-sEuE6mpyn9" id="image1-1f">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://openreview.net/forum?id=otswIbmgYA"><img src="assets/images/frameworkv6-1076x395.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Automatic radiologist report generation</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Automatic generation of radiologist report</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">We present Vispi, an automatic medical image interpretation system, which first annotates an image via classifying and localizing common thoracic diseases with visual support and then followed by report generation from an attentive LSTM model.  <br>Li, X., Cao, R., &amp; Zhu, D. (2020). <a href="https://openreview.net/forum?id=otswIbmgYA" class="text-primary">Vispi: Automatic visual perception and interpretation of chest X-rays</a>. In the proceedings of the Medical Imaging with Deep Learning (MIDL-20) conference, Montreal, CA.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content14 cid-tdsxc3BTBY" id="content14-1r">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7"><strong>AI for Science: </strong>AI has been increasingly applied to <strong>life</strong>, <strong>physical</strong> and <strong>social</strong> science domains to solve the real-world problems. In life science domain, I develop mining and learning algorithms to analyze the deep sequencing data (DNA-Seq or RNA-Seq). The Graphical User Interface software <a href="http://sammate.sourceforge.net/" class="text-primary">SAMMATE</a> has become a standard software suite in RNA-Seq data based research area. Other GUI software <a href="http://dsplicetype.sourceforge.net/" class="text-primary">dSpliceType</a>&nbsp;for detecting tissue specific differential splicing and <a href="https://code.google.com/archive/p/teak/" class="text-primary">TEAK</a> for detecting activated sub-pathways have also been widely used by the life science research community.&nbsp; &nbsp; &nbsp;</h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="image1 cid-tdsCMhhsbx" id="image1-1t">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="http://sammate.sourceforge.net/"><img src="assets/images/sammate-small-672x261.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">SAMMate: RNA-Seq data analysis software suite with GUI</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>RNA-Seq and Subpathway Analysis</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">Deng N, Puetter, A, Zhang, K, Johnson, K., Zhao, Z, Taylor, C, Flemington, E and Zhu, D. (2011) <a href="https://academic.oup.com/nar/article/39/9/e61/1254609?login=false" class="text-primary">Isoform-level microRNA-155 Target Prediction using RNA-seq</a>. <em>Nucleic Acids Res</em>., doi: 10.1093/nar/gkr042.  
<br>
<br>Judeh, T, Johnson, C, Kumar, A, Zhu, D (2013) <a href="https://academic.oup.com/nar/article/41/3/1425/2903069?login=false" class="text-primary">TEAK: Topological Enrichment Analysis frameworK for detecting activated biological subpathways</a>. <em>Nucleic Acids Res.</em>, doi: 10.1093/nar/gks1299.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="footer3 cid-sEd9n64OAA" once="footers" id="footer3-s">

    

    <div class="mbr-overlay" style="opacity: 0.4; background-color: rgb(255, 255, 255);"></div>

    <div class="container">
        <div class="media-container-row align-center mbr-white">
            <div class="row row-links">
                <ul class="foot-menu">
                    
                    
                    
                    
                    
                <li class="foot-menu-item mbr-fonts-style display-7"><a href="index.html" class="text-success">Home</a></li><li class="foot-menu-item mbr-fonts-style display-7"><a href="publications.html" class="text-success text-primary">Research</a></li><li class="foot-menu-item mbr-fonts-style display-7"><a href="teaching.html" class="text-success text-primary">Publication</a></li><li class="foot-menu-item mbr-fonts-style display-7"><a href="students.html" class="text-success text-primary">Teaching</a></li></ul>
            </div>
            
            <div class="row row-copirayt">
                <p class="mbr-text mb-0 mbr-fonts-style mbr-white align-center display-7">
                    © Copyright 2021- 2024 Dongxiao Zhu. All Rights Reserved.
                </p>
            </div>
        </div>
    </div>
</section><section class="display-7" style="padding: 0;align-items: center;justify-content: center;flex-wrap: wrap;    align-content: center;display: flex;position: relative;height: 4rem;"><a href="https://mobiri.se/2545557" style="flex: 1 1;height: 4rem;position: absolute;width: 100%;z-index: 1;"><img alt="" style="height: 4rem;" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw=="></a><p style="margin: 0;text-align: center;" class="display-7">&#8204;</p><a style="z-index:1" href="https://mobirise.com/html-builder.html">HTML Generator</a></section><script src="assets/bootstrap/js/bootstrap.bundle.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/ytplayer/index.js"></script>  <script src="assets/dropdown/js/navbar-dropdown.js"></script>  <script src="assets/theme/js/script.js"></script>  
  
  
</body>
</html>