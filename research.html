<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.3.10, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.3.10, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/logo.png" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Research</title>
  <link rel="stylesheet" href="assets/tether/tether.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">
  
  
  
  
</head>
<body>
  
  <section class="menu menu1 cid-sDmoM1B40a" once="menu" id="menu1-b">
    

    <nav class="navbar navbar-dropdown navbar-fixed-top navbar-expand-lg">
        <div class="container">
            <div class="navbar-brand">
                
                <span class="navbar-caption-wrap"><a class="navbar-caption text-black text-primary display-7" href="index.html">Dongxiao Zhu</a></span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <div class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#header11-6">Home</a></li><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="research.html">Research</a></li>
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="publications.html">Publication</a></li>
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="teaching.html">Teaching</a>
                    </li></ul>
                
                
            </div>
        </div>
    </nav>
</section>

<section class="content14 cid-sEd6OGNHu7" id="content14-p">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7">Our recent research thrust lies in trustworthy Artificial Intelligence (AI) algorithms with community driven innovations for social good, such as health and wellbeing, mobility equity, security and privacy. Our&nbsp;<strong>foundational AI research</strong> focuses on <strong>explainability</strong>, <strong>adversarial robustness</strong>, and <strong>fairness</strong> of deep neural networks (DNNs), collectively referring to trustworthy AI. Recent literature has focused much on the marked performance improvement of AI models, nevertheless overlooking trustworthiness when deploying the AI models in safety and security-critical real-world scenarios. Our foundational research subsequently motivates&nbsp;<strong>use-inspired research</strong> to tackle some of more pressing community-driven issues (e.g., disparities in health and mobility), via more efficiently leveraging the limited resources to improve accessibility of the socially vulnerable groups, fostering a thriving community.<br><strong><br></strong><strong>Explainability of DNNs Explainable AI (XAI)</strong> research attempts to understand how information flows from input to output. We have made original contributions to both directions of current XAI research: <strong>explainable model prediction</strong><span style="font-size: 1.2rem;"> and&nbsp;</span><strong>interpretable feature mapping</strong><span style="font-size: 1.2rem;">.</span><div>
</div></h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section class="image1 cid-sEoldobSNS" id="image1-17">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="assets/files/ijcai21_CRC.pdf"><img src="assets/images/discrimnating-793x292.jpg" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Adversarial Gradient Integration (AGI)</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Explaining DNN prediction</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">Adversarial Gradient Integration (AGI), to explain the contribution of each pixel, each word and/or each variable to the DNN’s prediction, such as image class or sentence sentiment.<br>Pan, D, Li, X and <strong>Zhu, D. </strong>(2021) <a href="assets/files/ijcai21_CRC.pdf" class="text-primary">Explaining Deep Neural Network Models with Adversarial Gradient Integration</a>. In 30th International Joint Conference on Artificial Intelligence (IJCAI-21), Montreal, Canada.<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="image1 cid-sEoj0IDD8I" id="image1-16">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://www.ijcai.org/proceedings/2020/373"><img src="assets/images/explain-ex-625x195.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Interpretable Feature Mapping (IFM)</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Interpretable feature mapping</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">An interpretable neural network architecture allowing interpretable feature mapping and demonstrated applications in explainable recommender’s system.<br>Pan, D, Li, X, Li, X and <strong>Zhu, D.</strong> (2020) <a href="https://www.ijcai.org/Proceedings/2020/0373.pdf" class="text-primary">Explainable recommendation via interpretable feature mapping and evaluating explainability</a>. In the proceedings of 29th International Joint Conference on Artificial Intelligence (IJCAI-20), Yokohama, Japan.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content14 cid-sEooiDLZnC" id="content14-18">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7"><strong>Adversarial robustness of DNNs </strong>research: we develop novel feature representation learning approaches to improve the adversarial robustness of the DNN via <strong>learning compact feature representation</strong>. I achieve this goal via designing novel <strong>natural training</strong> and <strong>adversarial training</strong> schemes. An important factor impacting feature representation learning is sampling mini-batches.</h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section class="image1 cid-sEopdyQtEz" id="image1-19">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17030/16837"><img src="assets/images/picture4-1076x424.png" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Probabilistically Compact (PC) loss
<br>with logit constraints</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Probabilistically Compact (PC) loss&nbsp;</strong><strong>with logit constraints</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">A new Probabilistically Compact loss (PC loss) to directly enlarge the probability gap between true class and false classes to improve adversarial robustness of DNNs.
<br>Li, X, Li, X, Pan,D and <strong>Zhu, D.</strong> (2021) <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/17337/15866" class="text-primary">Improving adversarial robustness via probabilistically compact loss with logit constraints</a>. In the proceedings of Thirty-Five AAAI Conference on Artificial Intelligence (AAAI-21), virtual conference.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content14 cid-sEoz0piasa" id="content14-1b">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7"><strong>Fairness of DNNs </strong>research: this includes mitigation of <strong>class-imbalance</strong> and <strong>group-imbalance</strong> issues. To mitigate group-imbalance issue, we developed Multi-Task Learning (MTL) algorithms to predict time-to-event and ordinal outcomes. To overcome class-imbalance issue, we developed a cost-sensitive approach to design optimal weight schemes. We explicated the learning property of logistic and softmax loss functions by analyzing the necessary condition (e.g., gradient equals to zero) after training converges.</h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section class="image1 cid-sEopevIV1t" id="image1-1a">
    

    

    <div class="container">
        <div class="row align-items-center">
            <div class="col-12 col-lg-6">
                <div class="image-wrapper">
                    <a href="https://ojs.aaai.org//index.php/AAAI/article/view/5907"><img src="assets/images/cifartsne-1-1076x551.jpg" alt="Mobirise"></a>
                    <p class="mbr-description mbr-fonts-style pt-2 align-center display-4">Interpretable Feature Mapping (IFM)</p>
                </div>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h3 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Learning property of softmax loss based DNNs</strong></h3>
                    <p class="mbr-text mbr-fonts-style display-7">A novel reweighted logistic loss for multi-class classification to improve ordinary logistic loss by focusing on learning hard non-target classes (target vs. non-target class in one-vs.-all) <br>Li, X, Li, X, Pan,D and <strong>Zhu, D.</strong> (2020) <a href="https://ojs.aaai.org//index.php/AAAI/article/view/5907" class="text-primary">On the learning behavior of logistic and softmax losses for deep neural networks</a>. In the proceedings of Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20), New York, USA.&nbsp;<br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content14 cid-sEoeeScyM9" id="content14-13">
    
    
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                    <h3 class="mbr-section-title mbr-fonts-style mb-4 display-7"><strong>Use-inspired Trustworthy AI Research: </strong>Healthcare data is featured with <strong>high dimension</strong>, <strong>heterogeneity</strong> and <strong>label scarcity</strong>. Our AI applications in healthcare research lies in patient subgroup identification and risk factor prioritization. To overcome label scarcity issue, we used primary labels together with auxiliary labels as regularization to learn features and improve prediction performance. We also tackle the label scarcity issue using semi-supervised and active learning approaches using EHR data. To address the data heterogeneity issue, we developed multi-task deep feature learning approaches to learn general features for predicting population-wide and task-specific features for predicting group-specific health outcomes. When patient groups are undefined, we generalized it with a deep mixture neural network model to predict health outcomes for latent groups. Our recent research thrust lies in trustworthy Artificial Intelligence (AI) algorithms with community driven innovations for social good, such as health and wellbeing, mobility equity, security and privacy.</h3>
                <ul class="list mbr-fonts-style display-4"></ul>
            </div>
        </div>
    </div>
</section>

<section class="footer3 cid-sEd9n64OAA" once="footers" id="footer3-s">

    

    <div class="mbr-overlay" style="opacity: 0.4; background-color: rgb(255, 255, 255);"></div>

    <div class="container">
        <div class="media-container-row align-center mbr-white">
            <div class="row row-links">
                <ul class="foot-menu">
                    
                    
                    
                    
                    
                <li class="foot-menu-item mbr-fonts-style display-7"><a href="index.html" class="text-success">Home</a></li><li class="foot-menu-item mbr-fonts-style display-7"><a href="publications.html" class="text-success text-primary">Research</a></li><li class="foot-menu-item mbr-fonts-style display-7"><a href="teaching.html" class="text-success text-primary">Publication</a></li><li class="foot-menu-item mbr-fonts-style display-7"><a href="students.html" class="text-success text-primary">Teaching</a></li></ul>
            </div>
            
            <div class="row row-copirayt">
                <p class="mbr-text mb-0 mbr-fonts-style mbr-white align-center display-7">
                    © Copyright 2021 Dongxiao Zhu. All Rights Reserved.
                </p>
            </div>
        </div>
    </div>
</section><section style="background-color: #fff; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif; color:#aaa; font-size:12px; padding: 0; align-items: center; display: flex;"><a href="https://mobirise.site/w" style="flex: 1 1; height: 3rem; padding-left: 1rem;"></a><p style="flex: 0 0 auto; margin:0; padding-right:1rem;"><a href="https://mobirise.site/d" style="color:#aaa;">This site</a> was made with Mobirise</p></section><script src="assets/web/assets/jquery/jquery.min.js"></script>  <script src="assets/popper/popper.min.js"></script>  <script src="assets/tether/tether.min.js"></script>  <script src="assets/bootstrap/js/bootstrap.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/dropdown/js/nav-dropdown.js"></script>  <script src="assets/dropdown/js/navbar-dropdown.js"></script>  <script src="assets/touchswipe/jquery.touch-swipe.min.js"></script>  <script src="assets/theme/js/script.js"></script>  
  
  
</body>
</html>